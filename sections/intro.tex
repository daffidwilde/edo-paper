\section{Introduction}\label{section:introduction}

\inputtikz{flowchart}{%
    A general schematic for an evolutionary algorithm.
}

\begin{itemize}
    \item What is the motivation?\\
    Here, a diagram might be useful to highlight the flipped paradigm. Typically one would fix some benchmark examples and a metric, and then assess the algorithm based on this metric. This paradigm has a number of problems:\\
    1. How were the benchmark examples selected? In some disciplines/domains there are well established benchmarks, in others less so. Sometimes a `new' data set is simulated to assess the performance of an algorithm. How and why is this simulation created?\\
    2. In disciplines where there are established benchmarks, there still may be problems e.g. (i) Work by Hyndman, who considered benchmark data sets used in time series analysis competitions, showed that the data sets were biased towards particular attributed; (ii) the amount of learning one can gain as to the attributes of data which lead to good (or bad) performance of an algorithm are constrained to the finite set of attributes present in the benchmark data chosen in the first place.
    \item What is the problem?
    \item What is the solution?
\end{itemize}

%-----------------------------
\subsection{Literature review}

\begin{itemize}
    \item How is artificial data made?
    \item Why hasn't this been done before?
    \item Genetic algorithms used to train algorithms for data
    \item Diagram showing that this is the ``reverse'' problem
\end{itemize}
