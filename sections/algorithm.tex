\section{The evolutionary algorithm}\label{section:algorithm}

\subsection{Structure}

In this section, the details of an algorithm that generates data for which a
given function or, equivalently, an algorithm which is well suited, is
described. This algorithm is to be referred to as ``Evolutionary Dataset
Optimisation'' (EDO).

The EDO method is built as an evolutionary algorithm which follows a traditional
(generic) schema with some additional features that keep the objective of
artificial data generation in mind. With that, there are a number of parameters
that are passed to EDO;\ the typical parameters of an evolutionary algorithm
are a fitness function, \(f\), which maps from an individual to a real number,
as well as a population size, \(N\), a maximum number of iterations, \(M\), a
selection parameter, \(b\), and a  mutation probability, \(p_m\). In addition to
these, EDO takes the following parameters:

\begin{itemize}
    \item Limits on the number of rows an individual dataset can have:
        \[
            R \in \left\{%
                (r_{\min}, r_{\max}) \in \mathbb{N}^2~|~r_{\min} \leq r_{\max}
            \right\}
        \]
    \item Limits on the number of columns a dataset can have:
        \[
            C := \left(C_1, \ldots, C_{|\mathcal{P}|}\right)
            ~\text{where}~
            C_j \in \left\{ (c_{\min}, c_{\max}) \in {%
                \left(\mathbb{N}\cup\{\infty\}\right)
            }^2~|~c_{\min} \leq c_{\max}\right\}
        \]
        for each \(j = 1, \ldots, |\mathcal{P}|\). That is, \(C\) defines the
        minimum and maximum number of columns a dataset may have from each
        distribution in \(\mathcal{P}\).
    \item A set of probability distribution families, \(\mathcal{P}\). Each
        family in this set has some parameter limits which form a part of the
        overall search space. For instance, the family of normal distributions,
        denoted by \(N(\mu, \sigma^2)\), would have limits on values for the
        mean, \(\mu\), and the standard deviation, \(\sigma\).
    \item A probability vector to sample distributions from \(\mathcal{P}\),
        \(w = \left(w_1, \ldots, w_{|\mathcal{P}|}\right)\).
    \item A second selection parameter, \(l \in [0, 1]\), to allow for a
        small proportion of ``lucky'' individuals to be carried forward.
    \item A shrink factor, \(s \in [0, 1]\), defining the relative size of a
        component of the search space to be retained after adjustment.
\end{itemize}

The concepts discussed in this section form the mechanisms of the evolutionary
dataset optimisation algorithm. To use the algorithm practically, these
components have been implemented in Python as a library built on the scientific
Python stack~\cite{pandas,numpy}. The library is fully tested and documented (at
\url{https://edo.readthedocs.io}) and is freely available online under the MIT
license~\cite{edo-project}. The EDO implementation was developed to be
consistent with the best practices of open source software development.
% TODO Citation(s) needed.

\input{tex/algorithms/edo.tex}\label{alg:edo}
\input{tex/algorithms/new_population.tex}

The statement of the EDO algorithm is presented here to lay out its general
structure from a high level perspective. Lower level discussion is provided
below where additional algorithms for the individual creation, evolutionary
operator and shrinkage processes are given along with diagrams (where
appropriate).

Note that there are no defined processes for how to stop the algorithm or adjust
the mutation probability, \(p_m\). This is down to their relevance to a
particular use case. Some examples include:

\begin{itemize}
    \item Stopping when no improvement in the best fitness is found within some
        \(K\) consecutive iterations~\cite{Leung2001}.
    \item Utilising global behaviours in fitness to indicate a stopping
        point~\cite{Marti2016}.
    \item Regular decreasing in mutation probability across the available
        attributes~\cite{Kuehn2013}.
\end{itemize}

\subsection{Individuals}

Evolutionary algorithms operate on succeeding populations of individuals often
coined as ``generations''. In a genetic algorithm, an individual would be
encoded as a bit string of a fixed length and treated as a chromosome-like
object to be manipulated. In EDO, as it is an evolutionary algorithm and the
objective is to generate datasets, there is no encoding process. Instead, the
datasets are manipulated directly so that the biological operators can be
designed and be interpreted in a more meaningful way.

\inputtikz{individual}{%
    An example of how an individual is first created.
}

In a sense, a dataset is treated similarly to a bit string in a genetic
algorithm as the primary components of the dataset are considered to be its
columns. As is seen in Figure~\ref{figure:individual}, an individual's creation
is defined by the generation of its columns. A set of instructions on how to
sample new values for that column are recorded in the form of a probability
distribution. These distributions are sampled from \(\mathcal{P}\).

A caveat to this: one should not assume that the columns are a reliable
representative of the distribution associated with them, or vice versa. This is
particularly true of ``shorter'' datasets with a small number of rows, whereas
confidence in the pair could be given more liberally for ``longer'' datasets
with a larger number of rows. In any case, appropriate methods should be
employed to understand the structure and characteristics of the data produced
before formal conclusions are made.

\input{tex/algorithms/individual.tex}

\subsection{Selection}

The selection operator describes the process by which individuals are chosen
from the current population to generate the next. Almost always, the likelihood
of an individual being selected is determined by their fitness. This is because
the purpose of selection is to preserve favourable qualities and encourage some
homogeneity within future generations~\cite{Back1994}.

\inputtikz[.8\textwidth]{selection}{%
    The selection process with the inclusion of some lucky individuals.
}
\input{tex/algorithms/selection.tex}

In EDO, a modified truncation selection method is used, as can be seen in
Figure~\ref{figure:selection}. Truncation selection takes a fixed number, \(n_b
= \lceil bN\rceil\), of the fittest individuals in a population and makes them
the ``parents'' of the next. The modification is an optional stage after the
best individuals have been chosen: by passing some small \(l\) to the
evolutionary algorithm, a number of the remaining individuals can be selected at
random to be carried forward. This number is given by \(n_l = \lceil lN
\rceil\). It should be noted that even with this modification, no individual may
be selected more than once in a single iteration but could potentially be
present throughout the run of the algorithm.

It has been shown that, despite its efficiency as a selection operator,
truncation selection can lead to premature convergence at local
optima~\cite{Jebari2013, Tatsuya2002}. Hence, allowing for the inclusion of a
small number of randomly selected individuals may encourage diversity and
exploration throughout the run of the algorithm.

\subsection{Crossover}

Crossover is the operation of combining two individuals in order to create at
least one offspring. In EDO, a method known as uniform crossover is
used~\cite{Semenkin2012}. Under this method, a new individual is created by
uniformly sampling each of its
components from a set of two ``parent'' individuals. As can be seen in
Figure~\ref{figure:crossover}, this method has been adapted for the dataset
representation, i.e.\ two parent datasets have their dimensions and then columns
sampled uniformly and without replacement to give a new individual.

\inputtikz{crossover}{The crossover process.}
\input{tex/algorithms/crossover.tex}

\subsection{Mutation}

Mutation is used in evolutionary algorithms to encourage a broader exploration
of the search space at each generation. Under this framework, the mutation
process acts on each characteristic of an individual: the dimensions, the column
metadata and the entries themselves. This process is described in
Figure~\ref{figure:mutation}, and is such that all aspects of the search space
are susceptible to mutation.

\inputtikz{mutation}{The mutation process.}

Each of the potential mutations occur with the same probability, \(p_m\), but
the way in which columns are maintained assure that (assuming appropriate
choices for \(f\) and \(\mathcal{P}\)) many mutations in the metadata and the
dataset itself will only result in some incremental change in the individual's
genetics and fitness overall \-- at least relatively so to, say, a completely
new individual.

\input{tex/algorithms/mutation.tex}

\subsection{Shrinking}

The potential benefits of adapting the search space of an EA has been
well-discussed in the domain of complex optimisation problems. During the
development of EDO, two methods were considered to do this. Each of these
methods relied on a law relating a successive generation's search space with its
predecessor. It should be noted that in both cases the methods were adapted to
conform with the choice to represent individuals as they are rather than as bit
strings.

The first was developed to be a two-part process based on a linear law with two
parameters: a shrink factor, \(s \in (0, 1)\), and the maximum number of
iterations \(M \in \mathbb{N}\)~\cite{Amirjanov2017}. The adapted method would
be as follows. For all iterations, \(t \geq sM\), no shrinking would take place.
However, for all previous iterations, the suggested method would take the
parents found during selection and act on each component of the search space.
That is, for each iteration, \(t < sM\), every component would have its lower
and upper limits, denoted by \(l_t\) and \(u_t\) respectively, adjusted so that
they are centred about the mean parent value, \(\mu\), and be such that:
\[
    u_{t+1} - l_{t+1} = (u_t - l_t) \left(1 - \frac{t}{sM}\right)
\]

More specifically, the adjusted limits would be calculated as follows:
\begin{align*}
    l_{t+1} = \max \left\{%
        l_t, \ \mu - \frac{1}{2} (u_t - l_t) \left(1 - \frac{t}{sM}\right)
    \right\}\\
    u_{t+1} = \min \left\{%
        u_t, \ \mu + \frac{1}{2} (u_t - l_t) \left(1 - \frac{t}{sM}\right)
    \right\}
\end{align*}

The second method was for use in a genetic algorithm which mapped weighted bit
strings to some pre-defined interval with lower and upper
bounds~\cite{Amirjanov2016}. The proposed method would rely on a power law with
a single parameter: some shrink factor, \(s \in [0, 1]\). Again, at each
iteration, the parents would be taken and every component's limits would be
adjusted so that they were centred about the mean parent value, \(\mu\), such
that:
\[
    u_{t+1} - l_{t+1} = (u_t - l_t) s^t
\]

The process by which the values of \(l_{t+1}\) and \(u_{t+1}\) would be found
are equivalent to the above but with a different shift term:
\begin{align}
    \label{eq:shrinking_lower}
    l_{t+1}&= \max \left\{l_t, \ \mu - \frac{1}{2} (u_t - l_t) s^t\right\}\\
    \label{eq:shrinking_upper}
    u_{t+1}&= \max \left\{u_t, \ \mu + \frac{1}{2} (u_t - l_t) s^t\right\}
\end{align}

From these brief definitions alone, these methods appear to be largely
indistinguishable. However, following a wider discussion around how EDO would
work for the general user, it was decided that the first method be rejected in
favour of the second. It was found that the second method having fewer
parameters was a particularly redeeming feature; this removed any hidden or
otherwise unwanted interactions between a parameter dedicated to the shrink
process, \(s\), and the maximum number of iterations, \(M\), which is often used
as a fallback stopping criterion in complex problem domains.

\input{tex/algorithms/shrinking.tex}
