\section{The evolutionary algorithm}\label{section:algorithm}

\subsection{Structure}

In this section, the details of an algorithm that generates data for which a
given function or, equivalently, an algorithm which is well suited, is
described. This algorithm is to be referred to as ``Evolutionary Dataset
Optimisation'' (EDO).

The EDO method is built as an evolutionary algorithm which follows a traditional
(generic) schema with some additional features that keep the objective of
artificial data generation in mind. With that, there are a number of parameters
that are passed to EDO. The typical parameters of an evolutionary algorithm
include:

\begin{itemize}
    \item A fitness function, \(f\), which maps from an individual to a real
        number.
    \item A population size, \(N\).
    \item A maximum number of iterations, \(M\).
    \item A selection proportion, \(b\), for the best individuals in a
        population
    \item A mutation probability, \(p_m\).
\end{itemize}

In addition to these, EDO takes the following parameters:

\begin{itemize}
    \item Limits on the number of rows a dataset can have:
        \[
            R \in \left\{%
                (r_{\min}, r_{\max}) \in \mathbb{N}^2~|~r_{\min} \leq r_{\max}
            \right\}
        \]
    \item Limits on the number of columns a dataset can have:
        \[
            C := \left(C_1, \ldots, C_{|\mathcal{P}|}\right)
            ~\text{where}~
            C_j \in \left\{ (c_{\min}, c_{\max}) \in {%
                \left(\mathbb{N}\cup\{\infty\}\right)
            }^2~|~c_{\min} \leq c_{\max}\right\}
        \]
        for each \(j = 1, \ldots, |\mathcal{P}|\). That is, \(C\) defines the
        minimum and maximum number of columns a dataset may have from each
        distribution in \(\mathcal{P}\).
    \item A set of probability distribution families, \(\mathcal{P}\). Each
        family in this set has some parameter limits which form a part of the
        overall search space. For instance, the normal distribution family,
        denoted by \(N(\mu, \sigma^2)\), would have limits on values for the
        mean, \(\mu\), and the standard deviation, \(\sigma\).
    \item A probability vector to sample distributions from \(\mathcal{P}\),
        \(w = \left(w_1, \ldots, w_{|\mathcal{P}|}\right)\).
    \item A second selection parameter, \(l \in [0, 1]\), to allow for a
        small proportion of ``lucky'' individuals to be carried forward.
    \item A shrink factor, \(s \in [0, 1]\). The relative size of a component of
        the search space to be retained after adjustment.
\end{itemize}

The concepts discussed in this section form the mechanisms of the evolutionary
dataset optimisation algorithm. To use the algorithm practically, these
components have been implemented in Python as a library built on the scientific
Python stack~\cite{pandas,numpy}. The library is fully tested and documented (at
\url{https://edo.readthedocs.io}) and is freely available online under the MIT
license~\cite{edo-project}. The EDO implementation was developed to be
consistent with the best practices of open source software development.
% TODO Citation(s) needed.

\input{tex/algorithms/edo.tex}\label{alg:edo}
\input{tex/algorithms/new_population.tex}

The statement of the EDO algorithm is presented here to lay out its general
structure from a high level perspective. Lower level discussion is provided
below where additional algorithms for the individual creation, evolutionary
operator and shrinkage processes are given along with diagrams (where
appropriate).

Note that there are no defined processes for how to stop the algorithm or adjust
the mutation probability, \(p_m\). This is down to their relevance to a
particular use case. Some examples include:

\begin{itemize}
    \item Stopping when no improvement in the best fitness is found within some
        \(K\) consecutive iterations~\cite{Leung2001}.
    \item Utilising global behaviours in fitness to indicate a stopping
        point~\cite{Marti2016}.
    \item Constant decreasing in mutation probability by varied amounts across
        the available attributes~\cite{Kuehn2013}.
\end{itemize}

\subsection{Individuals}

Evolutionary algorithms operate on succeeding populations of individuals often
coined as ``generations''. Typically, an individual would be encoded as a bit
string of a fixed length and treated as a chromosome-like object to be
manipulated. In EDO, as the objective is to generate datasets, there is no
encoding process. Instead, the datasets are manipulated directly so that the
biological operators can behave and be interpreted in a more meaningful way.

\inputtikz{individual}{%
    An example of how an individual is first created.
}

In a sense, a dataset is treated similarly to a classical bit string as the
primary components (loci) of the dataset are considered to be its columns. As is
seen in Figure~\ref{figure:individual}, an individual's creation is defined by
the random generation of its columns. A set of instructions on how to sample new
values for that column are recorded in the form of a probability distribution.
These distributions are sampled from a pool of distribution families which is
passed to the evolutionary algorithm along with the other parameters.

Obviously, users and interpreters of EDO should not be so quick to assume that
these pairs of distributions and columns are typical of their partner. That is,
that the columns are a reliable representative of the distribution associated
with them, or vice versa. A caveat to this statement: this is particularly true
of ``shorter'' datasets with a small number of rows, whereas confidence in the
pair could be given more liberally for ``longer'' datasets. In the case of the
latter, the column metadata can become more useful for casually analysing the
data which is generated. In any case, however, more direct and sophisticated
methods should be employed to understand the structure and characteristics of
the data before formal conclusions are made.

\input{tex/algorithms/individual.tex}

\subsection{Selection}

The selection operator describes the process by which individuals are chosen
from the current population to generate the next. Almost always, the likelihood
of an individual being selected is determined by their fitness. This is because
the purpose of selection is to preserve favourable qualities and encourage some
homogeneity within future generations.

\inputtikz[.9\textwidth]{selection}{%
    The selection process with the inclusion of some lucky individuals.
}

In EDO, a modified truncation selection method is used as can be seen in
Figure~\ref{figure:selection}. Standard truncation selection takes a fixed
number, \(n_b = \lceil bN\rceil\), of the fittest individuals in a population
and makes them the ``parents'' of the next. The modification is an optional
stage after the best individuals have been chosen. By passing some small \(l\)
to the evolutionary algorithm, a number of random individuals can be selected to
be carried forward. This number is given by \(n_l = \lceil lN \rceil\). It
should be noted that even with this modification, no individual may be selected
more than once in a single iteration but could potentially be present throughout
the entire run of the algorithm.

\input{tex/algorithms/selection.tex}

It has been found that, despite its efficiency as a selection
operator, truncation selection can lead an evolutionary algorithm to
converge prematurely to local optima~\cite{Jebari2013}. Hence, the ability to
include some randomly selected individuals is included to encourage diversity
throughout the run of the algorithm. This feature can be particularly useful in
more complex optimisation scenarios \-- or for larger populations where a
greater loss of diversity is seen in the selection process simply due to the
nature of truncation selection~\cite{Tatsuya2002}. As such, it should be used
sparingly so as not to dominate the selection process with unwanted randomness.

\subsection{Crossover}

Crossover is the operation of combining two individuals in order to create at
least one offspring. Often in classical evolutionary algorithms, the term
``crossover'' is taken literally: two bit strings are crossed at a point
to produce two new bit strings. Another popular method is uniform crossover
where the loci of a new individual are sampled uniformly from either parent
individual. This method is adapted to support dataset manipulation here by
sampling first a set of dimensions from the parents, and then inheriting entire
columns.

\inputtikz{crossover}{The crossover process.}

\input{tex/algorithms/crossover.tex}

\subsection{Mutation}

Mutation is used in evolutionary algorithms to encourage a broader exploration
of the search space. Traditional applications with chromosome representations
would mutate by run along the loci of an individual and ``switching'' the binary
value with some constant probability. Under this framework, as has been
discussed, an individual's columns are similar to traditional loci. However, in
the mutation phase multiple characteristics of an individual are susceptible to
being mutated beyond the columns themselves such as the dimensions of the
individual and their column metadata.

\inputtikz{mutation}{The mutation process.}

The mutation process, seen in Figure~\ref{figure:mutation} and defined in
Algorithm~\ref{algorithm:mutation},
is deliberately fine so that all aspects of an individual can be changed in a
meaningful yet fluid way. Each of the potential mutations occur with the same
probability, \(p_m\), but the way in which columns are maintained assure that
(assuming appropriate choices for \(f\) and \(\mathcal{P}\)) many mutations in
the metadata and the dataset itself will only result in some incremental change
in the individual's genetics and fitness overall \-- at least relatively so to,
say, a completely new individual.

\input{tex/algorithms/mutation.tex}

\subsection{Shrinking}

The potential benefits of adapting the search space of an EA has been
well-discussed in the domain of complex optimisation problems. During the
development of EDO, two methods were considered to do this. Each of these
methods relied on a law relating a successive generation's search space with its
predecessor. It should be noted that in both cases the methods were adapted to
conform with the choice to represent individuals as they are rather than as bit
strings.

The first was developed to be a two-part process based on a linear law with two
parameters: a shrink factor, \(s \in (0, 1)\), and the maximum number of
iterations \(M \in \mathbb{N}\)~\cite{Amirjanov2017}. The adapted method would
be as follows. For all iterations, \(t \geq sM\), no shrinking would take place.
However, for all previous iterations, the suggested method would take the
parents found during selection and act on each component of the search space.
That is, for each iteration, \(t < sM\), every component would have its lower
and upper limits, denoted by \(l_t\) and \(u_t\) respectively, adjusted so that
they are centred about the mean parent value, \(\mu\), and be such that:
\[
    u_{t+1} - l_{t+1} = (u_t - l_t) \left(1 - \frac{t}{sM}\right)
\]

More specifically, the adjusted limits would be calculated as follows:
\begin{align*}
    l_{t+1} = \max \left\{%
        l_t, \ \mu - \frac{1}{2} (u_t - l_t) \left(1 - \frac{t}{sM}\right)
    \right\}\\
    u_{t+1} = \min \left\{%
        u_t, \ \mu + \frac{1}{2} (u_t - l_t) \left(1 - \frac{t}{sM}\right)
    \right\}
\end{align*}

The second method was for use in a genetic algorithm which mapped weighted bit
strings to some pre-defined interval with lower and upper
bounds~\cite{Amirjanov2016}. The proposed method would rely on a power law with
a single parameter: some shrink factor, \(s \in [0, 1]\). Again, at each
iteration, the parents would be taken and every component's limits would be
adjusted so that they were centred about the mean parent value, \(\mu\), such
that:
\[
    u_{t+1} - l_{t+1} = (u_t - l_t) s^t
\]

The process by which the values of \(l_{t+1}\) and \(u_{t+1}\) would be found
are equivalent to the above but with a different shift term:
\begin{align}
    \label{eq:shrinking_lower}
    l_{t+1}&= \max \left\{l_t, \ \mu - \frac{1}{2} (u_t - l_t) s^t\right\}\\
    \label{eq:shrinking_upper}
    u_{t+1}&= \max \left\{u_t, \ \mu + \frac{1}{2} (u_t - l_t) s^t\right\}
\end{align}

From these brief definitions alone, these methods appear to be largely
indistinguishable. However, following a wider discussion around how EDO would
work for the general user, it was decided that the first method be rejected in
favour of the second. It was found that the second method having fewer
parameters was a particularly redeeming feature; this removed any hidden or
otherwise unwanted interactions between a parameter dedicated to the shrink
process, \(s\), and the maximum number of iterations, \(M\), which is often used
as a fallback stopping criterion in complex problem domains.

\input{tex/algorithms/shrinking.tex}
